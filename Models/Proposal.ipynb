{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Appling Synthetic Control Methodology </center>\n",
    "\n",
    "<center>By Jiaoping Chen </center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.thoughtco.com/thmb/FzU2MP1eoOe6ZbD7T2bsVTWatmc=/768x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/control-and-experimental-group-differences-606113-FINAL1-5b7ad7d0c9e77c00574b71b5.png\" width=\"100%\">\n",
    "\n",
    "Image from https://www.thoughtco.com/control-and-experimental-group-differences-606113\n",
    "\n",
    "**NOTE:** This image should either be avaliable on the Internet (in which case you include the full url in the ```src``` field.  Or, the image should be added to your repository in the ```docs/images``` directory in which case the ```src``` field should be a relative path such as ```./images/myfile.png```. DO NOT use absolute paths for local files. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Overview\n",
    "\n",
    "Although the number of submitted papers in the computer science conference is explosively increasing, especially in the artificial intelligence and machine learning areas, the lack of replicability might hinder the spread of the influence of CS communities, at the early stage. Some researchers might prefer to share their codes with other readers but most are not. Thus, I am very curious if this mentioned-code-link behavior affects the paper's impact, such as the number of citations, if so, what is the magnitude of true effect? \n",
    "\n",
    "My goal is to estimate how the number of citations differs as a result of the mentioned-code-link behavior. However, endogeneity issues occur if we do not account for unobservable properties that may both make the author share codes and also boost the paper's citation counts, such that he/she is a pioneer in a specific area. This endogeneity issue leads to a biased estimate of our interesting variable. Therefore, I introduce a synthetic control method to identify the causal effect, or the Average Treatment Effect (ATE) by comparing the performance of each treated observation to that of similar untreated observations.\n",
    "\n",
    "Specifically, given a treated observation, a synthetic control can be constructed by combining similar untreated samples into a weighted average. In other words, even if we don't know the counterfactual outcome, we can still utilize a weighted average of similar untreated observations to proxy the outcome. A valid synthetic control should reasonably approximate the treated observation.\n",
    "\n",
    "In this project, I will firstly pre-process two large datasets (>10G) using python and then write a synthetic control algorithm to construct the control group for the treatment\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Program Description\n",
    "\n",
    "I already downloaded two datasets but haven't had a chance to preprocess and clean up the data. So this project will include two main components. \n",
    "\n",
    "- First, I will create a *\"Pre-process.py\"* python file to generate the cleaned version of two datasets. The first dataset is to obtain the response variable (the number of a paper's citation), the other is for the independent variable (whether the paper mentioned its 'Github link' to share open code resource). After that, I will match those two datasets to get my raw samples with my interested variables. Here, I define the treated group as articles that mention their corresponding Github links, while the \"candidates\" for the control group are those not mention code resources. (the candidate control group refers to the control group without synthetic control.)\n",
    "\n",
    "\n",
    "- Second, I will create a *\"Syn_control.py\"* to apply a synthetic control method to select controls for my treatment group. I decide to write codes by myself. It is an optimization problem that aims to select weights to minimize pre-treatment differences between treated and untreated groups. Then, I will generate a table to show similar statistics characteristics for both treated and control groups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Project Goals and Timeline\n",
    "\n",
    "**Short Term** Read and clean large datasets using efficient python codes; Understand the Synthetic control algorithm and apply it to solve the real-world problem.\n",
    "\n",
    "**Mid Term** Write the log-likelihood function using python code; Solve it through the optimization toolkit. \n",
    "\n",
    "**Long Term** Collect more related variables for the response, the number of papers' citations. For example, extracting each paper's abstract and then do topic modeling, since the number of citation can be affected by the type of article. \n",
    "\n",
    "As a reminder, here are a set of dates (Approx. every other Friday) that include deliverables related to your projects. These sub-projects are designed to introduce you to useful software development tools\n",
    "\n",
    "\n",
    "- 9/11/2020 - Create git repository \n",
    "- 9/25/2020 - Proposal Due\n",
    "- 10/02/2020 - Upload the data and then star the pre-process datasets\n",
    "- 10/09/2020 - Stub functions and Example code integration (With documentation)\n",
    "- 10/16/2020 - finish datacleaning, and then get raw samples;\n",
    "- 10/23/2020 - Unit Test Integration\n",
    "- 10/30/2020 - finish Reading main algorithms \n",
    "- 11/06/2020 - Coding Standaqrds and Linting\n",
    "- 11/13/2020 - write/debug the algorithm \n",
    "- 11/20/2020 - Code Review \n",
    "- 12/04/2020 - Presentation Video Due\n",
    "- 12/09/2020 - Final Report and Code due.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Anticipating Challenges  \n",
    "\n",
    "I need to learn how to read very large JSON in python (>10G), how to pre-process them efficiently, how to use Github to manage my code files and resources, and how to turn the mathematics language into python codes.\n",
    "\n",
    "I suspect I will encounter two main challenges. 1) pre-processing data directly with the JSON format because it is hard to generate large data frames using pandas; 2) writing code for the synthetic control algorithm. (If I cannot figure them out, I will apply the synthetic control method using available packages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Proposal Grading Rubric\n",
    "The following basic grading rubric was used last semester.  It may change slightly but should give an idea of what is considered important. \n",
    "\n",
    "    Grading Overall\n",
    "    10 points - Project title\n",
    "    10 points - Descriptive picture\n",
    "    20 points - Overview\n",
    "    20 points - Program Description\n",
    "    20 points - Project Goals / Timeline\n",
    "    20 points - Anticipating Challenges\n",
    "\n",
    "    Grading Rubric\n",
    "    -5 Leaving in instructions in report.\n",
    "    -5 Sloppy formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Congratulations, you are done!\n",
    "\n",
    "Commit your proposal in markdown or ipynb format to your ```docs``` directory in your project git repository on or before **11:59pm on Friday September 25**."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
